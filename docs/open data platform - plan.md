# Open Data Platform - Plano de Implementa√ß√£o

## Objetivo

Construir um Lakehouse funcional camada a camada, utilizando componentes open source do ecossistema Cloudera Data Platform (CDP), com um case de processamento de dados de transporte p√∫blico (SPTrans - API Olho Vivo).

---

## Diagrama da Arquitetura

```mermaid
flowchart TB
    subgraph SOURCES["üì• Fontes de Dados"]
        API["üöå API SPTrans<br/>Olho Vivo"]
        CSV["üìÑ CSV<br/>Bilhetagem"]
    end

    subgraph INGESTION["üì° Ingest√£o"]
        SR["Schema Registry<br/>:8081"]
        NIFI["Apache NiFi<br/>:8080"]
    end

    subgraph STORAGE["üíæ Storage Layer"]
        MINIO["MinIO<br/>:9000/:9001"]
        subgraph BUCKETS["Arquitetura Medallion"]
            LANDING["üü° Landing<br/>JSON/CSV"]
            BRONZE["üü† Bronze<br/>Iceberg"]
            SILVER["‚ö™ Silver<br/>Iceberg"]
            GOLD["üü° Gold<br/>Iceberg"]
        end
        HMS["Hive Metastore<br/>:9083"]
    end

    subgraph PROCESSING["‚öôÔ∏è Processamento"]
        SPARK["Apache Spark<br/>:8082/:7077"]
        GE["Great Expectations"]
    end

    subgraph QUERY["üîç Query Layer"]
        HIVE["Apache Hive<br/>:10000"]
        BI["üìä BI Tools"]
    end

    subgraph GOVERNANCE["üîê Governan√ßa"]
        RANGER["Apache Ranger<br/>:6080"]
        ATLAS["Apache Atlas<br/>:21000"]
    end

    subgraph ORCHESTRATION["üéØ Orquestra√ß√£o"]
        AIRFLOW["Apache Airflow<br/>:8085"]
    end

    subgraph MONITORING["üìà Monitoramento"]
        PROMETHEUS["Prometheus<br/>:9090"]
        GRAFANA["Grafana<br/>:3000"]
    end

    subgraph BACKEND["üóÑÔ∏è Backend"]
        PG["PostgreSQL<br/>:5432"]
    end

    %% Fluxo de Ingest√£o
    API --> NIFI
    CSV --> NIFI
    NIFI <--> SR
    NIFI --> LANDING

    %% Storage
    LANDING --> MINIO
    BRONZE --> MINIO
    SILVER --> MINIO
    GOLD --> MINIO
    HMS <--> MINIO

    %% Processamento
    SPARK --> LANDING
    SPARK --> BRONZE
    SPARK --> SILVER
    SPARK --> GOLD
    SPARK <--> HMS
    GE -.-> SPARK

    %% Query
    HIVE <--> HMS
    HIVE --> GOLD
    HIVE --> BI

    %% Governan√ßa
    RANGER -.-> HIVE
    RANGER -.-> SPARK
    ATLAS <--> HMS
    ATLAS -.-> SPARK

    %% Orquestra√ß√£o
    AIRFLOW --> NIFI
    AIRFLOW --> SPARK

    %% Backend
    PG --> HMS
    PG --> SR
    PG --> AIRFLOW
    PG --> RANGER
    PG --> ATLAS

    %% Monitoramento
    PROMETHEUS -.-> MINIO
    PROMETHEUS -.-> SPARK
    PROMETHEUS -.-> NIFI
    PROMETHEUS -.-> AIRFLOW
    GRAFANA --> PROMETHEUS
```

---

## Arquitetura

### Stack Tecnol√≥gico

| Componente | Fun√ß√£o | Equivalente CDP |
|------------|--------|-----------------|
| MinIO | Object Store S3-compatible | Ozone |
| Hive Metastore | Cat√°logo de tabelas Iceberg | HMS |
| Apache NiFi | Ingest√£o e roteamento | Cloudera DataFlow |
| Schema Registry | Contratos de dados | Cloudera Schema Registry |
| Apache Spark | Processamento distribu√≠do | Cloudera Data Engineering |
| Apache Iceberg | Formato de tabela open | Iceberg CDP |
| Apache Ranger | Pol√≠ticas de seguran√ßa | Ranger CDP |
| Apache Atlas | Governan√ßa e linhagem | Atlas CDP |
| Apache Airflow | Orquestra√ß√£o de pipelines | Airflow CDE |
| Apache Hive | Query engine SQL | Hive/Impala CDW |

### Arquitetura Medallion

| Camada | Bucket | Formato | Descri√ß√£o |
|--------|--------|---------|-----------|
| Landing | `s3://landing/` | JSON/CSV | Dados brutos exatamente como recebidos |
| Bronze | `s3://bronze/` | Iceberg | Dados convertidos, particionados, sem transforma√ß√£o |
| Silver | `s3://silver/` | Iceberg | Dados limpos, validados, enriquecidos |
| Gold | `s3://gold/` | Iceberg | Agregados prontos para consumo |

### Fluxo de Dados

1. **Ingest√£o** - NiFi autentica na API SPTrans, valida payload contra Schema Registry, grava em Landing
2. **Bronze** - Spark converte JSON/CSV para Iceberg, adiciona metadados de ingest√£o
3. **Silver** - Spark aplica Great Expectations, realiza joins e enriquecimento
4. **Gold** - Spark gera agregados de performance, demanda e bilhetagem
5. **Consulta** - Hive exp√µe camada Gold via SQL para BI
6. **Governan√ßa** - Ranger aplica mascaramento e RBAC, Atlas rastreia linhagem

---

## Estrat√©gia de Implanta√ß√£o

> **Abordagem Incremental:** Cada servi√ßo ser√° implantado manualmente via `docker run`, validado individualmente e integrado aos demais antes de avan√ßar. Ap√≥s compreens√£o completa do funcionamento, ser√° consolidado em `docker-compose.yml` final.

| Ordem | Servi√ßo | Depend√™ncia |
|-------|---------|-------------|
| 1 | MinIO | Nenhuma |
| 2 | PostgreSQL | Nenhuma |
| 3 | Hive Metastore | PostgreSQL, MinIO |
| 4 | Schema Registry | PostgreSQL |
| 5 | NiFi | Schema Registry, MinIO |
| 6 | Spark | Hive Metastore, MinIO |
| 7 | Great Expectations | Spark |
| 8 | Hive (Query Engine) | Hive Metastore, MinIO |
| 9 | Ranger | PostgreSQL |
| 10 | Atlas | PostgreSQL, Hive Metastore |
| 11 | Airflow | PostgreSQL, todos os anteriores |
| 12 | Prometheus + Grafana | Todos os servi√ßos |
| 13 | Docker Compose | Consolida√ß√£o final |

---

## Steps

### Step 1: MinIO (Object Store)

Implantar object store S3-compatible como funda√ß√£o do data lake.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | minio/minio |
| Portas | 9000 (S3 API), 9001 (Console) |
| Volumes | Diret√≥rio local para persist√™ncia |
| Depend√™ncia | Nenhuma |

**Buckets a criar:**

| Bucket | Prop√≥sito |
|--------|-----------|
| landing | Dados brutos (JSON/CSV) |
| bronze | Tabelas Iceberg sem transforma√ß√£o |
| silver | Tabelas Iceberg limpas e enriquecidas |
| gold | Tabelas Iceberg agregadas |

**Valida√ß√£o:**
- Acessar console em http://localhost:9001
- Criar buckets: landing, bronze, silver, gold
- Testar upload/download via console ou CLI (mc)

---

### Step 2: PostgreSQL (Backend de Metadados)

Implantar banco de dados para Hive Metastore, Schema Registry e Airflow.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | postgres:15 |
| Porta | 5432 |
| Volumes | Diret√≥rio local para persist√™ncia |
| Depend√™ncia | Nenhuma |

**Databases a criar:**

| Database | Prop√≥sito |
|----------|-----------|
| metastore | Backend Hive Metastore |
| schemaregistry | Backend Schema Registry |
| airflow | Backend Airflow |
| ranger | Backend Ranger |
| atlas | Backend Atlas |

**Valida√ß√£o:**
- Conectar via psql ou cliente SQL
- Criar databases listados
- Verificar permiss√µes de usu√°rio

---

### Step 3: Hive Metastore (Cat√°logo Iceberg)

Implantar cat√°logo de tabelas integrado ao MinIO.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/hive |
| Porta | 9083 (Thrift) |
| Depend√™ncia | PostgreSQL, MinIO |

**Configura√ß√£o:**
- Backend PostgreSQL para metadados
- Endpoint S3 apontando para MinIO
- Warehouse em s3a://bronze/

**Valida√ß√£o:**
- Verificar conex√£o com PostgreSQL
- Testar cria√ß√£o de database via beeline
- Verificar comunica√ß√£o com MinIO

---

### Step 4: Schema Registry (Contratos de Dados)

Implantar registro de schemas para valida√ß√£o de payloads.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | confluentinc/cp-schema-registry |
| Porta | 8081 |
| Depend√™ncia | PostgreSQL |

**Schemas a registrar:**

| Schema | Vers√£o | Descri√ß√£o |
|--------|--------|-----------|
| sptrans.bus_position | v1 | Posi√ß√£o em tempo real dos √¥nibus |
| sptrans.bus_line | v1 | Informa√ß√µes das linhas |
| sptrans.bus_stop | v1 | Informa√ß√µes das paradas |
| billing.transaction | v1 | Eventos de bilhetagem simulados |

**Pol√≠tica de evolu√ß√£o:** BACKWARD (compatibilidade com consumidores existentes)

**Valida√ß√£o:**
- Acessar API em http://localhost:8081
- Registrar schema de teste via curl
- Consultar schemas registrados

---

### Step 5: Apache NiFi (Ingest√£o)

Implantar ferramenta de ingest√£o e roteamento de dados.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/nifi |
| Porta | 8080 (UI) |
| Depend√™ncia | Schema Registry, MinIO |

**Flows a criar:**

| Flow | Fonte | Destino | Valida√ß√£o |
|------|-------|---------|-----------|
| SPTrans Posi√ß√£o | API /Posicao | landing/sptrans/position/ | sptrans.bus_position.v1 |
| SPTrans Linhas | API /Linha/Buscar | landing/sptrans/lines/ | sptrans.bus_line.v1 |
| SPTrans Paradas | API /Parada/Buscar | landing/sptrans/stops/ | sptrans.bus_stop.v1 |
| Bilhetagem CSV | Arquivo local | landing/billing/ | billing.transaction.v1 |

**Valida√ß√£o:**
- Acessar UI em http://localhost:8080
- Configurar conex√£o com MinIO (S3)
- Testar ingest√£o de arquivo para landing/

---

### Step 6: Apache Spark (Processamento)

Implantar cluster Spark para transforma√ß√µes de dados.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | bitnami/spark |
| Portas | 8082 (Master UI), 7077 (Master), 8083 (Worker) |
| Depend√™ncia | Hive Metastore, MinIO |

**Configura√ß√£o:**
- JARs: iceberg-spark, hadoop-aws, aws-java-sdk
- Endpoint S3 apontando para MinIO
- Cat√°logo Hive via Thrift

**Jobs a desenvolver:**

| Job | Origem | Destino | Fun√ß√£o |
|-----|--------|---------|--------|
| landing_to_bronze | landing/* | bronze/* | Convers√£o Iceberg + metadados (_ingested_at, _source_file) |
| bronze_to_silver | bronze/* | silver/* | Valida√ß√£o + joins + limpeza |
| silver_to_gold | silver/* | gold/* | Agregados de performance, demanda e bilhetagem |

**Valida√ß√£o:**
- Acessar UI em http://localhost:8082
- Executar spark-shell conectado ao Hive Metastore
- Testar leitura/escrita de arquivo do MinIO

---

### Step 7: Great Expectations (Qualidade de Dados)

Configurar valida√ß√µes de qualidade para pipeline Bronze ‚Üí Silver.

| Aspecto | Detalhe |
|---------|---------|
| Instala√ß√£o | pip install great-expectations |
| Integra√ß√£o | Spark jobs |
| Depend√™ncia | Spark |

**Expectativas a definir:**

| Tipo | Valida√ß√£o |
|------|-----------|
| Completude | Campos obrigat√≥rios n√£o nulos |
| Formato | Datas, coordenadas, IDs v√°lidos |
| Range | Latitude (-90 a 90), Longitude (-180 a 180) |
| Unicidade | IDs de linha e parada √∫nicos |

**Valida√ß√£o:**
- Executar suite de expectativas via Spark
- Gerar relat√≥rio HTML
- Verificar dados rejeitados em quarentena

---

### Step 8: Apache Hive (Query Layer)

Implantar engine SQL para acesso √† camada Gold.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/hive |
| Porta | 10000 (HiveServer2 JDBC), 10002 (Web UI) |
| Depend√™ncia | Hive Metastore, MinIO |

**Funcionalidades:**

| Recurso | Descri√ß√£o |
|---------|-----------|
| Endpoint JDBC | Conex√£o para ferramentas BI via HiveServer2 |
| Predicate Pushdown | Otimiza√ß√£o de queries Iceberg |
| Integra√ß√£o Ranger | Pol√≠ticas de seguran√ßa nativas |
| Time Travel | Consultas hist√≥ricas via Iceberg |

**Valida√ß√£o:**
- Acessar Web UI em http://localhost:10002
- Conectar via beeline (CLI)
- Executar query em tabela Gold

---

### Step 9: Apache Ranger (Seguran√ßa)

Implantar servi√ßo de pol√≠ticas de acesso e mascaramento.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/ranger |
| Porta | 6080 (Admin UI) |
| Depend√™ncia | PostgreSQL |

**Pol√≠ticas a criar:**

| Pol√≠tica | Escopo | Regra |
|----------|--------|-------|
| Mascaramento PII | Campo card_id | Hash para n√£o-admin |
| Acesso por Camada | Buckets | Analistas apenas Gold |
| RBAC | Roles | admin, analyst, developer |

**Valida√ß√£o:**
- Acessar Admin UI em http://localhost:6080
- Criar pol√≠tica de teste
- Verificar auditoria de acessos

---

### Step 10: Apache Atlas (Governan√ßa)

Implantar servi√ßo de linhagem e classifica√ß√£o de dados.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/atlas |
| Porta | 21000 (UI) |
| Depend√™ncia | PostgreSQL, Hive Metastore |

**Funcionalidades:**

| Recurso | Descri√ß√£o |
|---------|-----------|
| Linhagem | API SPTrans ‚Üí NiFi ‚Üí Landing ‚Üí Spark ‚Üí Bronze ‚Üí Silver ‚Üí Gold |
| Classifica√ß√£o PII | Identifica√ß√£o autom√°tica de dados sens√≠veis |
| Gloss√°rio | Termos de neg√≥cio do dom√≠nio de transporte |
| Busca | Interface web para navega√ß√£o de metadados |

**Valida√ß√£o:**
- Acessar UI em http://localhost:21000
- Verificar integra√ß√£o com Hive Metastore
- Visualizar linhagem de tabela

---

### Step 11: Apache Airflow (Orquestra√ß√£o)

Implantar orquestrador de pipelines.

| Aspecto | Detalhe |
|---------|---------|
| Imagem | apache/airflow |
| Porta | 8085 (UI) |
| Depend√™ncia | PostgreSQL, todos os servi√ßos anteriores |

**DAG Principal (mobility_analytics_daily):**

| Ordem | Tarefa | Depend√™ncia |
|-------|--------|-------------|
| 1 | Trigger NiFi | - |
| 2 | Sensor Landing Zone | 1 |
| 3 | Spark Landing ‚Üí Bronze | 2 |
| 4 | Spark Bronze ‚Üí Silver | 3 |
| 5 | Spark Silver ‚Üí Gold | 4 |
| 6 | Notifica√ß√£o | 5 |

**Configura√ß√µes:**
- Retry com backoff exponencial
- SLA monitoring
- Alertas de falha

**Valida√ß√£o:**
- Acessar UI em http://localhost:8085
- Ativar DAG de teste
- Verificar execu√ß√£o de tarefas

---

### Step 12: Prometheus + Grafana (Monitoramento)

Implantar stack de monitoramento para m√©tricas e dashboards.

| Aspecto | Detalhe |
|---------|---------|
| Imagem Prometheus | prom/prometheus |
| Porta Prometheus | 9090 |
| Imagem Grafana | grafana/grafana |
| Porta Grafana | 3000 |
| Depend√™ncia | Todos os servi√ßos (coleta m√©tricas) |

**M√©tricas a coletar:**

| Servi√ßo | M√©tricas |
|---------|----------|
| MinIO | Requests, lat√™ncia, espa√ßo |
| Spark | Jobs, dura√ß√£o, sucesso/falha |
| NiFi | FlowFiles, backpressure, throughput |
| Hive | Queries ativas, tempo de resposta |
| Airflow | DAGs, tasks, SLA violations |

**Dashboards iniciais:**
- Sa√∫de dos servi√ßos (UP/DOWN)
- Pipeline de dados (registros por camada)
- Jobs Spark (dura√ß√£o, status)
- Alertas ativos

**Valida√ß√£o:**
- Acessar Prometheus em http://localhost:9090
- Acessar Grafana em http://localhost:3000
- Verificar targets ativos no Prometheus
- Visualizar dashboard de sa√∫de

---

### Step 13: Consolida√ß√£o Docker Compose

Ap√≥s valida√ß√£o individual de todos os servi√ßos, consolidar em docker-compose.yml.

| Aspecto | Detalhe |
|---------|---------|
| Arquivo | docker-compose.yml |
| Rede | dataplatform-network |
| Volumes | Mapeados para persist√™ncia |

**Entreg√°veis:**
- docker-compose.yml com todos os servi√ßos
- Vari√°veis de ambiente em .env
- Scripts de inicializa√ß√£o
- Documenta√ß√£o de uso

**Valida√ß√£o:**
- Destruir todos os containers individuais
- Executar `docker-compose up -d`
- Verificar healthchecks de todos os servi√ßos
- Testar pipeline fim-a-fim

---

## Artefatos

### Arquivos a Criar

| Artefato | Prop√≥sito | Execu√ß√£o |
|----------|-----------|----------|
| docker-compose.yml | Orquestra√ß√£o de containers (consolida√ß√£o final) | Manual (Step 13) |
| init-buckets.sh | Cria√ß√£o de buckets MinIO | Manual (Step 1) |
| prometheus.yml | Configura√ß√£o de targets Prometheus | Manual (Step 12) |
| grafana-dashboards/*.json | Dashboards de monitoramento | Manual (Step 12) |
| schemas/*.avsc | Schemas Avro para Schema Registry | Manual (Step 4) |
| nifi-flows/*.xml | Templates de flows NiFi | Manual (Step 5) |
| spark-jobs/*.py | Jobs Spark (Landing‚ÜíBronze‚ÜíSilver‚ÜíGold) | Manual (Step 6) |
| great-expectations/*.json | Suites de expectativas | Manual (Step 7) |
| ranger-policies/*.json | Pol√≠ticas de seguran√ßa | Manual (Step 9) |
| airflow-dags/*.py | DAGs de orquestra√ß√£o | Manual (Step 11) |

### Dados de Exemplo

| Arquivo | Descri√ß√£o |
|---------|-----------|
| sample-billing.csv | Transa√ß√µes fict√≠cias de bilhetagem |
| sample-positions.json | Posi√ß√µes de √¥nibus para teste |

---

## Fontes de Dados

### API Olho Vivo - SPTrans

| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| /Login/Autenticar | POST | Obten√ß√£o de token |
| /Posicao | GET | Posi√ß√£o dos ve√≠culos |
| /Linha/Buscar | GET | Busca de linhas |
| /Parada/Buscar | GET | Busca de paradas |

**Documenta√ß√£o:** https://www.sptrans.com.br/desenvolvedores/

### Bilhetagem Simulada

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| card_id | string | ID do cart√£o (PII) |
| line_id | string | ID da linha |
| timestamp | datetime | Data/hora da transa√ß√£o |
| stop_id | string | ID da parada |
| fare_type | string | Tipo de tarifa |

---

## Execu√ß√£o

### Setup Incremental (Step by Step)

Cada servi√ßo √© implantado e validado individualmente:

1. Executar `docker run` do servi√ßo conforme Step
2. Validar funcionamento isolado
3. Configurar integra√ß√£o com servi√ßos anteriores
4. Validar comunica√ß√£o entre servi√ßos
5. Avan√ßar para pr√≥ximo Step

### Consolida√ß√£o Final (Step 13)

1. Destruir todos os containers individuais
2. Criar docker-compose.yml consolidado
3. Executar `docker-compose up -d`
4. Validar pipeline fim-a-fim

### Execu√ß√£o Recorrente (p√≥s-consolida√ß√£o)

1. DAG `mobility_analytics_daily` executa automaticamente via Airflow
2. Monitorar execu√ß√£o via interface Airflow
3. Monitorar m√©tricas via Grafana
4. Consultar dados agregados via Hive

---

## Valida√ß√£o

### Crit√©rios de Aceite por Step

| Step | Servi√ßo | Crit√©rio |
|------|---------|----------|
| 1 | MinIO | Console acess√≠vel, buckets criados |
| 2 | PostgreSQL | Conex√£o funcional, databases criados |
| 3 | Hive Metastore | Conex√£o com PostgreSQL e MinIO, database criado |
| 4 | Schema Registry | API acess√≠vel, schema registrado |
| 5 | NiFi | UI acess√≠vel, dados chegando em landing/ |
| 6 | Spark | UI acess√≠vel, leitura/escrita no MinIO |
| 7 | Great Expectations | Relat√≥rio HTML gerado |
| 8 | Hive | Queries SQL retornando dados |
| 9 | Ranger | Mascaramento funcionando para n√£o-admin |
| 10 | Atlas | Linhagem visualiz√°vel |
| 11 | Airflow | DAG executando tarefas |
| 12 | Prometheus + Grafana | M√©tricas coletadas, dashboards funcionais |
| 13 | Docker Compose | Todos os servi√ßos healthy, pipeline fim-a-fim |

---

## Rollback

### Por Step Individual

- Parar container: `docker stop <container_name>`
- Remover container: `docker rm <container_name>`
- Remover volume se necess√°rio: `docker volume rm <volume_name>`
- Reiniciar Step espec√≠fico

### Rollback Total

1. Parar todos os containers
2. Remover volumes persistentes
3. Limpar imagens: `docker system prune`
4. Reiniciar do Step 1
